# HDFS settings
CLUSTER_NAME=test
CORE_CONF_fs_defaultFS=hdfs://namenode:8020
HDFS_CONF_dfs_namenode_name_dir=file:///hadoop/dfs/name
HDFS_CONF_dfs_datanode_data_dir=file:///hadoop/dfs/data
HDFS_CONF_dfs_replication=1

# Hive settings
#HIVE_METASTORE_USER=hive
#HIVE_METASTORE_PASSWORD=hive
#HIVE_METASTORE_DB=metastore
#HIVE_METASTORE_HOST=hive-metastore-postgresql
#HIVE_METASTORE_PORT=5432
#HIVE_CORE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://hive-metastore-postgresql:5432/metastore
#HIVE_CONF_hive_metastore_uris=thrift://hive-metastore:9083

# Metastore JDBC Connection
HIVE_CORE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://hive-metastore-postgresql:5432/metastore
HIVE_CORE_CONF_javax_jdo_option_ConnectionDriverName=org.postgresql.Driver
HIVE_CORE_CONF_javax_jdo_option_ConnectionUserName=hive
HIVE_CORE_CONF_javax_jdo_option_ConnectionPassword=hive

# Metastore URI for clients (like hive-server) to connect to
HIVE_CONF_hive_metastore_uris=thrift://hive-metastore:9083

# Location for Hive data in HDFS
HIVE_CORE_CONF_hive_metastore_warehouse_dir=/user/hive/warehouse

# Spark settings (optional)
SPARK_MASTER=spark://spark-master:7077
